### Operating System

> ##### 中断、异常与系统调用

- ARMv8


> ##### 操作系统结构

- 操作系统的复杂性
    - 不同目标之间往往存在冲突和权衡
    - 用户目标要求多功能，系统目标追求简单
    - 降低复杂性的途经：动态可变的策略，静态支持的机制
- 宏内核 (Monolithic Kernel)
    - 内核-应用两层
    - 优势：丰富的沉淀
    - 劣势：结构性缺陷（没有强隔离机制，实时性支持，系统过于庞大）
    - 不支持：
        1. scaling
        2. 硬件异构
        3. 安全
        4. 确定性时延
- 微内核 (Micro Kernel)
    - 最小化内核功能，模块间使用IPC
    - Mach：性能比较差，实现了IPC、系统调用重定向、用户态多进程、分布式支持
    - L3/L4：极大提升IPC性能
    - seL4：被形式化证明的微内核
    - QNX：满足航空安全和实时性
    - Google Fuchsia：试图覆盖多个领域
    - MINIX：教学用的微内核
    - 优点：易扩展移植、可靠、安全、健壮
    - 缺点：性能差、生态差、重用宏内核问题
    - 混合内核架构：
        - macOS/iOS = Mach微内核 + BSD 4.3 + 系统框架
        - Windows NT = 微内核 + 内核态的系统服务 + 系统框架

- 外核+库OS (ExoKernExel + LibOS)
    - ExoKernExel只负责管理应用，LibOS只负责服务应用
    - 将硬件抽象打包成库的形式提供，高度定制化
    - 安全绑定：利用software TLB实现计算资源的隔离
    - 显式资源回收与中止协议
    - Unikernel：只提供一个进程的服务，适应容器
    - 优点：OS没有抽象，理论上提供最优性能、更精确的实时控制、用户态容易调试
    - 缺点：甩锅，效率主要由应用决定，定制化过多导致的维护难度增加

- 多内核 (Multi-Kernel)
    - 随着CPU core越来越多，单个OS疲于管理众多core，最好每个core有一个内核

> ##### 内存管理

- 物理内存
    - 早期，单个应用+操作系统，直接面向物理内存，各自使用一部分
    - 多重编程时代
        - 分时复用CPU、物理内存：全部内存写入磁盘开销太大
        - 同时使用、各占一部分物理内存：没有安全性（隔离性）
    - Protection Key：内存固定分块，CPU检查进程与内存key的匹配
        - 支持了应用隔离，但受地址绑定
    - 使用物理地址的缺点：物理地址对应用可知
        1. 受其他应用影响
        2. 可以猜测到其他应用位置
    - 结构
        - Channel DIMM Rank Chip Bank Row Column
    - buddy system - 管理页，按2的幂次分割和合并，解决外部碎片
    - SLAB - 页内分配，解决内部碎片
    - 安全问题
        - Rowhammer攻击
        - Cache Side Channel攻击
    - 性能问题
        - cache miss开销很高

- 虚拟内存
    - 所有软件（包括OS）均使用虚拟地址，无法直接访问物理地址
    - 虚拟地址会被硬件翻译成物理地址
    - CPU --虚拟地址--> MMU --物理地址--> 物理内存
    - 分段机制
        - 分配粒度太粗，利用率低
    - 分页机制
        - 关键是虚拟页号到物理页号的映射
        - 单级页表耗费大量空间，多级页表允许出现“空洞”，从而减少空间占用
        - 实际64位应用中只使用了48位虚拟空间
        - AARCH64 - TTBR(Translation Table Base Register)页表基地址寄存器
        - x86_64 - CR3寄存器
    - 页表使能
        - 默认物理寻址
        - AARCH64 - SCTLR第0位置1
        - x86_64 - CR4第31位置1
    - 页表页
    - 页表项
        - 包括有效位（是否有子级页表）、是否可以执行位、读写权限位、访问异常位、多核共享位、是否cache位

- Cached Lockdown（Arm特性）
    - 配置cache不被evict，驻留在CPU内部
    - 提高性能，永远hit
    - 提高安全性，限制部分数据永远不离开CPU

- TLB (Translation Lookaside Buffer)
    - 页表事实上是时间换空间的设计，增加了访存次数
    - 位于CPU内部，由硬件管理，缓存有限数目的虚拟页号到物理页号的映射关系
    - 在一些体系结构(MIPS)中，TLB由软件管理，更加灵活
    - 在地址翻译过程中，MMU首先查询TLB，命中则fast path，未命中再查询页表
    - TLB在切换页表时需要全部刷新
        - AArch64上内核和应用使用不同的页表，并同时存在TTBR0——EL1和TTBR1——EL1，系统调用不用切换
        - x86-64只有唯一CR3，内核映射到页表高地址来避免系统调用时TLB刷新开销
        - 降低刷新开销：
            - 为不同页表打标签，TLB缓存项都有标签，切换页表时不需要刷新TLB
            - x86_64 PCID
            - AArch64 ASID
        - 多核场景：单进程多线程需要刷新其他核的TLB
    - 全局TLB，对于全局共享的只读项

- 物理内存的超售和按需分配
    - 换页机制
        - 将物理内存放不下的内容放到磁盘，而虚拟内存不受物理内存限制
        - 在磁盘上划分专门的Swap分区，处理缺页异常时触发物理内存页的换入换出
    - 缺页异常
        - 异常时跳转到缺页异常处理函数
        - x86_64: CR2
        - AArch64 FAR_EL1
    - 按需分配中的权衡
        - 利用时空局部性，进行预取prefetching
    - 页替换策略
        - 随即替换
        - FIFO
        - LRU/MRU
        - Clock Algorithm
    - Thrashing Problem
        - 频繁的缺页异常导致大部分CPU时间都被用来处理缺页异常
    - 工作集模型
        - 让一个进程的工作集要不都在内存中，否则全部换出，all-or-nothing
- 今天物理内存容量增大，价格下降，非易失性内存出现，换页机制已经不那么重要
- 内存管理
    - 共享内存
    - copy-on-write
    - 内存去重
    - 内存压缩
    - 大页

> ##### 进程和线程

- 进程
    - 进程是对任务的抽象，是运行中的程序，在分时操作系统中的概念
        - 静态：代码和数据
        - 动态：运行时状态（PC、堆、栈）
    - 进程具有独立的虚拟地址空间，形成独占内存的假象，内核中同样包含内核栈和内核代码、数据
    - 单一线程的进程中：线程管理/调度 = 进程管理/调度
    - 进程的状态：
        - new：初始化
        - running：运行中
        - ready：可以被调度
        - blocked：等待，短时间内不能运行
        - terminated：完成执行
    - 进程的数据结构PCB：进程标识符、内存、打开的文件、上下文context
    - 上下文切换：中断/系统调用进入内核，上下文保存在PCB中
    - 进程的基本操作：
        - fork：创建一模一样的新进程，拥有不同的进程id，并行执行，共享部分内存、文件
            - 建立父子进程关系，形成进程树/进程组
            - Copy-On-Write
            - 优点：接口简单、将创建和执行解耦、刻画了进程间关系（进程树）
            - 缺点：完全拷贝粗暴、性能查、可扩展性差、不可组合性（fork+pthread）
            - vfork：父子进程共享地址空间，无需拷贝但只能用在fork+exec，且存在安全问题。（由CopyOnWrite取代）
            - posix_spawn：相当于fork+exec，可扩展、性能好
            - clone：高度可控的fork，接口复杂
        - exec：载入可执行文件后会重置地址空间
        - wait
        - exit/abort

- 线程
    - 出现的原因：
        1. 创建进程开销大：数据、代码、堆、栈
        2. 进程隔离性太强：IPC开销很大
        3. 进程内部无法支持并行
    - 线程是更加轻量级的运行时抽象，只包含运行时状态（寄存器和栈），一个进程可以包含多个线程，分别运行在不同处理器上
    - 内核态线程：内核可见，由内核创建，线程相关信息存放在内核中
    - 用户态线程：内核不可见，在应用态创建，线程相关信息存放在应用数据中
    - 线程模型
        - 多对一模型：多个用户态线程对应一个内核态线程
            - 优点：内核管理简单
            - 缺点：可扩展性差
            - 用于各种用户态线程库
        - 一对一模型：一个用户态线程对应一个内核态线程
            - 优点：解决了可扩展性问题
            - 缺点：内核线程数量大，开销大
            - 主流操作系统都采用一对一（Windows、Linux、OS X）
        - 多对多模型（Scheduler Activation）：多个用户态线程对应多个内核态线程
            - 优点：解决了可扩展和线程过多的问题
            - 缺点：管理更复杂
            - 在虚拟化中广泛应用
    - 线程的数据结构TCB：
        - 内核态与PCB结构类似，task_struct
        - 应用态由线程库定义，pthread/TIB
    - 线程本地存储TLS：允许定义每个线程独有的数据
    - 线程的基本操作：
        - pthread_create
        - pthread_join：等待线程完成获取其结果，类似fork的逆向操作
        - pthread_exit
        - pthread_yield：暂停线程
    - 线程切换：两次权限等级切换，三次栈切换
        1. 进入内核态，保存上下文（寄存器、PC、SP、CPU状态）
        2. 调度下一个线程，切换页表和内核栈
        3. 恢复上下文，返回用户态

- 调度
    - 本质：协调各种请求对于资源的使用
    - 目标：降低周转时间、降低响应时间、实时性、公平性、开销低、可拓展
    - 挑战：缺少工作场景信息、线程/任务间复杂交互、调度目标的多样性、tread-off（调度开销/调度效果、优先级/公平、能耗/性能）
    - 策略：做什么，分析解决问题
    - 机制：怎么做，实现策略功能
    - 每种调度机制可以对应多个调度策略
    - First Come First Served
    - Shortest Job First
    - Preemptive Scheduling: Round Robin
    - Multi-level Queue
    - 公平共享：
        - Lottery Scheduling：随机简单，但不精确
        - 权重-分配比例，优先-使用顺序
        - Stride Scheduling：确定版本的Lottery Scheduling
        - LinuxComplete Fair Scheduler

- 进程间通信
    - 进程协作的好处：
        1. 模块化，可复用
        2. 专注，加速计算
        3. 信息共享，避免重复计算
    - 共享内存：如何同步？
        - 发送者不能覆盖未读取数据
        - 接收者不能读没准备好的数据
        - 接收者不能读别人的数据
        - 简单轮询：浪费资源
    - 消息传递：低时延，不浪费资源
        - 直接通信：Recv阻塞，直到接收到Send消息
        - 间接通信：创建一个MessageBox，多个接收者Recv
        - 同步通信：阻塞等待，增加超时机制
        - 异步通信：不阻塞
        - 通信缓存：零容量/有限容量/无限容量
    - UNIX经典IPC
        - Unix管道：单向的简介消息传递方式（ls | grep）
            - 实现通过一个缓存区域，一个进程写，一个进程读，依赖于Sleep/Wakeup通信机制
            - Sleep/Wakeup：是经典进程间wait/notify机制，Channel是等待和通知的媒介。 一个进程可以通过sleep接口将自己等待在一个信道上，另外一个进程可以通过wakeup将等待在某个信道上的进程唤醒。
            - 缺点：缺少消息类型、缓冲区大小固定、只支持单向通信、最多支持两个进程通信
        - 消息队列：链表组织，带类型的消息传递，可以有多个发送者和接收者，FIFO+基于类型的查询
    - 轻量级远程方法调用LRPC
        - 控制流转换：解决调度导致不确定时延的问题，将调用者运行在被调用上下文，共享参数栈和寄存器

> ##### 多核多处理器与性能可扩展性

- 正确性保证：同步原语
    - 临界区三个要求：
        1. 互斥访问
        2. 有限等待
        3. 空闲让进
    - 基本原语
        - 软件：皮特森算法
        - 硬件：
            - CAS(CompareAndSwap):Intel锁总线实现、arm使用LL/SC实现
            - FetchAndAdd
    - 互斥锁：
        - Spinlock：有可能饥饿，空闲让进依赖于硬件
        - Ticket Lock：保证了公平性
    - 读写锁：
        - 偏向性：读取状态下，写者后来的读者能否进入读。
            - 偏向写者，不能进入，更加公平
            - 偏向读者，可以进入，更好的并行性
    - RCU(Read Copy Update)：读者不要拿读锁，要么读到旧值，要么读到新值，不会读到中间结果
        - 硬件原子操作有大小限制（128 bit）
        - Single-copy atomicity：更新一个指针，实现一个操作原子可见
        - 局限性：复制空间的开销，不知道何时回收旧空间
        - 宽限期
    - 管程：提供开发者线程安全的接口，相当于monitor
    - 死锁：拿着锁等锁
        - 互斥访问、持有并等待、资源非抢占、循环等待
        - 解决：
            1. 出问题再处理：检测环，kill重来
            2. 设计时避免死锁：
               1. 避免互斥访问，e.g. LockServer
               2. 不允许持有并等待，e.g. trylock (可能导致Live Lock)
               3. 允许资源抢占
               4. 打破循环等待，按顺序获取资源
            3. 死锁避免：运行时检查，e.g. 银行家算法
    - 优先级反转：双重调度导致（操作系统的优先级调度和按锁的调度）
        - 不可打断临界区协议(Non-preemptive Critical Sections, NCP)：拿锁后禁止操作系统调度
        - 优先级继承协议(Priority Inheritance Protocol, PIP)：高优先级进程被阻塞时，继承给锁持有者
        - 即时优先级置顶协议 (Immediate Priority Ceiling Protocols, IPCP)：拿到锁优先级就最高
        - 原生优先级置顶协议 (Original Priority Ceiling Protocols, OPCP)：高优先级进程被阻塞时，直接给锁进程最高优先级

- 性能保证
    - 理想中核越多越快，实际上并不好
    - Amdahl's Law: $S = \frac{1}{(1-p) + \frac{p}{s}}$ 加速比最大是$S = \frac{1}{(1-p)}$
    - 多核缓存一致性：MSI状态转移
        - M(Modified)：本地写独占
        - S(Shared)：有人读
        - I(Invalid)：其他核写
    - 可扩展性断崖：所有核竞争单一缓存行，维持一致性本身的顺序开销增加，可并行代码占比减少
    - MCS锁：
    - 非一致性内存访问
        - AKA
        - NUMA：跨节点访问性能变差
        - cohort锁
    - 内存模型
        - LockOne：
        - 严格一致性：全局时钟下严格顺序执行
        - 顺序一致性：局部时钟下顺序执行
        - TSO一致性：只有写-读顺序不能保证
        - 弱序一致性：不做任何保证
            - barrier：任何访存操作不会逾越内存屏障


> ##### 多核多处理器与性能可扩展性

- 基于inode的文件系统
    - Ext2
        - 常规文件：12个直接指针，1个间接指针，1个二级，1个三级
        - 目录文件：
- 基于Table的文件系统
    - FAT32
        - 不支持4G以上
        - exFAT拓展size的大小
        - U盘使用这种文件系统更简单，降低写操作
        - 设计中就没有考虑支持link
        - 随机读取文件慢，需要遍历FAT表
        - 坏一个块会损坏后面所有的数据
    - NTFS
        - 查找文件很快，有MFT索引
        - 存取小文件很高效，直接嵌入到MFT中保存
- 虚拟文件系统VFS
    - 中间层，对上提供POSIX API，对下对接不同的文件系统驱动


- 文件系统高级功能
    - Mac的APFS秒复制超大文件，CoW
    - 快照，CoW
    - 稀疏文件，直接记录此处全0
    - 加密、压缩、去重、校验、RAID
- 文件系统的多种形式
    - Git实际是个内容寻址的文件系统
    - SQLite表面是个数据库，实际也可以是一个文件系统，对小文件效率更高
- FUSE


> ##### 崩溃一致性

- 文件系统的崩溃一致性
- 一些文件系统操作所要求的属性
    - 持久化：哪些操作是可见的
    - 原子性：要不都可见，要不都不可见
    - 有序性：保证顺序的可见
- 崩溃一致性保障方法
    - 原子更新技术
        - 日志：修改之前先记录到日志，修改完毕后，删除日志，适合频繁小量修改
            - 减少磁盘写：批量处理
            - 日志提交：定时触发，定量出发，用户触发(fsync)
            - Writebakc Mode：最快，但一致性最差
            - Ordered Mode：最常用
            - Journal Mode：一致性最好，但数据写两次
        - Copy-on-Write：数据复制一份修改，递归实现原子操作，适合整块修改
    - Soft updates：一些不一致情况是良性的

- 日志文件系统

> ##### 新型文件系统

- F2FS

> ##### 设备管理

- 设备抽象
    - 字符设备：LED、键盘、串口 = 字符抽象：read/write
        - 顺序访问
    - 块设备：闪存 = 块抽象：read/write，mmap
        - 随机访问
    - 网络设备：Ethernet网卡 = 网络抽象：socket
        - 格式化报文顺序访问
- 设备与操作系统交互
    - 可编程IO
        - Port IO
        - MMIO
    - DMA

- 中断
    - 不能太快

- 管理设备
    - 设备的代码——驱动
    - 驱动模型：
        - 越来越多的驱动推动了模板化开发

> ##### 网络

- 分层模型
    1. 应用层
    2. 传输层：TCP/UDP
    3. 网络层：IP
    4. 数据链路层：网络设备驱动
    5. 物理层
- DPDK

> ##### 系统虚拟化

- 优势：
    1. 服务器整合：提高资源利用率
        - 单个物理机资源利用率低
        - 降低云服务提供商的成本
    2. 方便程序开发
        - 调试操作系统
        - 测试应用程序的兼容性
    3. 简化服务器管理
        - 通过软件接口管理虚拟机
        - 虚拟机热迁移

- 接口
    - ISA：区分硬件和软件
    - ABI：提供操作系统服务或硬件功能
    - API：不同用户态提供的接口

- 虚拟化的特性：
    1. 提供与原先硬件一样的接口
    2. 性能略差一点
    3. VMM/Hypervisor控制所有物理资源

- Hypervisor分类
    - Type-1：直接运行在硬件上，性能损失少，e.g. Xen
    - Type-2：依托于Host OS，易于实现和安装，e.g. QEMU/KVM

- 虚拟化流程
    1. 捕捉所有系统ISA，trap
    2. 有具体指令实现相应虚拟化：处理器虚拟化，内存虚拟化，设备虚拟化 
    3. 回到虚拟机继续执行

- 处理器虚拟化
    - 问题：有些敏感指令无法trap
    - 方案：
        1. 解释执行：一条一条指令翻译
        2. 二进制翻译
        3. 半虚拟化：让客户虚拟机主动配合，而不是自以为是真实环境
        4. 硬件虚拟化：
            - Intel VT-x：Non-root Mode
            - ARM VHE：EL2

    - VCPU是用线程模拟CPU
    - QEMU/KVM
        - QEMU负责策略，KVM负责机制，QEMU调用KVM提供的接口

- 内存虚拟化
    - 目标：为虚拟机提供虚拟物理地址空间，隔离不同虚拟机地址空间
    - GVA->GPA->HPA
    - Shadow Page Table：提供直接从GVA到HPA的映射
    - Direct Page Table
    - 硬件虚拟化

- IO虚拟化
    - 设备模拟：在VM中模拟设备，由QEMU模拟执行，再交给真实设备
    - 半虚拟化：虚拟机内运行前端(front-end)驱动，VMM内运行后端(back-end)驱动，Hypercall，共享内存
    - 设备直通：虚拟机直接管理物理设备
        - 问题1：DMA恶意读写内存
        - 问题2：设备独占

- 中断虚拟化
    - 打断虚拟机执行
    - 不打断虚拟机执行

> ##### 轻量级虚拟化

- On-Premises IaaS CaaS PaaS FaaS
- Serverless：无服务部署，请求到来时新建服务器实例，执行后销毁
- Chroot：
    - 文件系统视图的隔离：改变当前进程的文件系统根目录
    - 无法实现彻底隔离（文件共享，共用IP，root权限）
- Container（LXC）
    - Linux Namespace-安全隔离：彼此不被看到
        1. Mount Namespace：容器内外共享文件系统
        2. IPC Namespace：不同容器共享IPC对象
        3. Network Namespace：不同容器共用IP
        4. PID Namespace：对内外NS的PID单向隔离
        5. User Namespace：对内外NS的UID和GID进行映射
        6. UTS Namespace：每个NS有独立的hostname
        7. Cgroup Namespace
        - Docker
        - Google Could Functions：Dune->gVisor
        - AWS Lambda/Firecracker
    - 性能隔离：彼此性能互不影响

> ##### 操作系统安全

- 操作系统安全的三个层次
    - 层次一：基于OS的应用隔离与访问控制
    - 层次二：OS对恶意应用的隔离与防御
    - 层次三：OS不可信时对应用的保护
- 概念
    - 可信计算基
    - 攻击面
    - 防御纵深

- 访问控制：认证+授权
    - 引用监视器
    - 认证：知道什么/有什么/是什么
    - 授权：权限矩阵
    - 最小特权级：SUID机制，临时提权，解决用户修改密码的矛盾
    - 基于角色的访问控制（RBAC）：将用户与角色解耦，e.g. 用户组
    - 自主访问控制DAC：谁能访问由所有者决定
    - 强制访问控制MAC：如何访问完全由底层系统决定
    - Bell-LaPadula模型：2MAC（高级别数据不会流入低级别）+DAC（同级别流通）
    - Capability：是权限矩阵的实现方法之一，e.g. fd

- SELINUX
    - 是Flask安全架构在Linux上的实现，是一个Linux内核的安全模块（LSM）

- 操作系统内部安全
    - 整形溢出漏洞
    - Return-to-user攻击
    - ret2dir
    - Rootkit
    - KASLR：内核地址布局随机化

- IOS的系统安全
    - 文件加密保护机制
    - 进程沙盒机制

-侧信道与隐秘信道
    - 隐秘信道：原本无法直接通信的双方，通过原本不被用于通信的机制进行数据传输（两方串通）
    - 侧信道：与隐秘信道类似（被攻击者无意中泄露给攻击者）
    - 缓存信道：利用缓存状态推测执行的信息
        - Flush+Reload
        - Flush+Flush
        - Evict+Reload
        - Prime+Probe
    - 防御
        - 侧信道攻击很难完全防御，根本方法是不共享
        - 常量时间算法
        - 不经意随机访问内存（ORAM）
    - Meltdown与KPTI


> ##### 硬件辅助系统安全

- 硬件Enclave：可信执行环境
    - 
